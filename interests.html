<!DOCTYPE html>
<html>
        <head>
                <meta charset="utf-8">
              
                <title>About me </title>
                <meta name="description" content="About me page">
                <meta name="author" content="Michał Podgórny">
                <meta name="viewport" content="width=device-width, initial-scale=1" />
                <link rel="stylesheet" href="css/styles.css?v=1.0">
                <link href="https://fonts.googleapis.com/css?family=Staatliches&display=swap" rel="stylesheet">

              
        </head>
    <body>
            <header id="title">
                    Interests
                    </header>

                    <article>
                        <header>
                            In IT:
                        </header>
                        <header>Machine learning</header>
                        There are many different types of machine learning algorithms, with hundreds published each day, and they’re typically grouped by either learning style (i.e. supervised learning, unsupervised learning, semi-supervised learning) or by similarity in form or function (i.e. classification, regression, decision tree, clustering, deep learning, etc.). Regardless of learning style or function, all combinations of machine learning algorithms consist of the following:
Representation (a set of classifiers or the language that a computer understands)
Evaluation (aka objective/scoring function)
Optimization (search method; often the highest-scoring classifier, for example; there are both off-the-shelf and custom optimization methods used)
The fundamental goal of machine learning algorithms is to generalize beyond the training samples i.e. successfully interpret data that it has never ‘seen’ before.
                    <header>Deepfake algorithm</header>
                    Academic research related to deepfakes lies predominantly within the field of computer vision, a subfield of computer science often grounded in
                     artificial intelligence that focuses on computer processing of digital images and videos. An early landmark project was the Video Rewrite 
                     program, published in 1997, which modified existing video footage of a person speaking to depict that person mouthing the words contained in a different audio track.[7] It was the first system to fully automate this kind of facial reanimation, and it 
                    did so using machine learning techniques to make connections between the sounds produced by a video's subject and the shape of their face.
Contemporary academic projects have focused on creating more realistic videos and on making techniques simpler, faster, and more accessible. The “Synthesizing Obama” 
program, published in 2017, modifies video footage of former president Barack Obama to depict him mouthing the words contained in a separate audio track.[8] The project 
lists as a main research contribution its photorealistic technique for synthesizing mouth shapes from audio. The Face2Face program, published in 2016, 
modifies video footage of a person's face to depict them mimicking the facial expressions of another person in real time.[9] The project lists as a main research contribution the first method for re-enacting facial expressions in real time using a camera that does not capture depth, making it possible for the technique to be performed using common consumer cameras.
</article>

                    <article>
                        <header>Outside IT:
                        </header>
                        <header>Running</header>
                        <header>Coffe</header>
                        <header>Pizza</header>
                    </article>
        </body>